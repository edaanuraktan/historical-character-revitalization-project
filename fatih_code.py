import os
import numpy as np
from scipy.io.wavfile import write
import torch

from TTS.api import TTS

# Gerekli konfigÃ¼rasyon sÄ±nÄ±flarÄ±nÄ± iÃ§e aktaracaÄŸÄ±z
from TTS.tts.configs.xtts_config import XttsConfig, XttsArgs
from TTS.tts.models.xtts import XttsAudioConfig
from TTS.config.shared_configs import BaseDatasetConfig

from torch.serialization import safe_globals

# TÃ¼m gerekli sÄ±nÄ±flarÄ± gÃ¼venli hale getiriyoruz
with safe_globals([XttsConfig, XttsAudioConfig, BaseDatasetConfig, XttsArgs]):
    tts = TTS(model_name="tts_models/multilingual/multi-dataset/xtts_v2", gpu=False)


# Ses Ã¶rneÄŸi dosyasÄ±
speaker_wav_path = "audio/fatih_sample.wav"

# KullanÄ±lacak metin dosyalarÄ±
text_files = [
    "text/fatih_text1.txt",
    "text/fatih_text2.txt",
    "text/fatih_text3.txt",
    "text/fatih_text4.txt",
    "text/fatih_text5.txt",
    "text/fatih_text6.txt",
    "text/fatih_text7.txt"
]

# TÃ¼m sesleri birleÅŸtirmek iÃ§in liste
combined_audio = []

# Sampling rate (XTTS iÃ§in Ã¶nerilen)
sample_rate = 24000

# Her metni iÅŸleyip sesi oluÅŸturacaÄŸÄ±z
for file_path in text_files:
    if not os.path.exists(file_path):
        print(f"âŒ Dosya bulunamadÄ±: {file_path}")
        continue

    with open(file_path, "r", encoding="utf-8") as f:
        text = f.read().strip()

    print(f"ğŸ”Š Metin okunuyor ve ses oluÅŸturuluyor: {file_path}")
    audio_array = tts.tts(
        text=text,
        speaker_wav=speaker_wav_path,
        language="tr"
    )

    combined_audio.append(audio_array)

# Sesleri birleÅŸtirip kaydetmek iÃ§in
if combined_audio:
    final_audio = np.concatenate(combined_audio)
    output_path = "audio/fatih_voice.wav"
    write(output_path, sample_rate, final_audio.astype(np.float32))
    print(f"âœ… BirleÅŸtirilmiÅŸ ses kaydedildi: {output_path}")
else:
    print("âŒ HiÃ§bir ses Ã¼retilemedi.")
